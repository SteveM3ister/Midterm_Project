---
title: "United States Home Health Care Analysis"
author: "Yinfeng Zhou"
date: "2020/11/26"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(drat)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(magrittr)
library(viridis)
library(lubridate)
library(kableExtra)
library(ggpubr)
library(MASS)
library(VGAM)
library(rstanarm)
library(arm)
library(bayesplot)
library(reshape2)
library(ordinal)
```

#Introduction

This project is meant to implement certain data analysis on the United States Home Health Care Dataset. The motivation of this analysis is to help understanding what factors contributes to a better home health care in rating, and thus help getting knowledge on how we should improve home health care and what the future direction will be in this field. The dataset used in this report is downloaded from Data.Medicare.Gov.

The dataset includes a number of variables that provides measurements of the quality of the home care services. Among the variables that are directly related to the home care service, there are 6 binary variables and 17 continuous variables. The binary varibales answer those "Yes or No" questions: `Offers Nursing Care Services`, `Offers Physical Therapy Services`, `Offers Occupational Therapy Services`, `Offers Speech Pathology Services`, `Offers Medical Social Services`, `Offers Home Health Aide Services`. The continuous varibales mainly answer those "How often" questions, using the measure percentage as reported. For example, in the variable `How often the home health team began their patients' care in a timely manner`, the number indicates the percentage of the home health team having begun their patients' care in a timely manner.    

The outcome we are interested in is the `Quality of patient care star rating`. Although this variable is collected as a numeric rating from 1 through 5, in increments of 0.5, we can treat it as categorical outcomes with 9 possible outcomes. 

In this report, we are mainly interested in how those continuous variables are correlated with the quality rating, building up a model for prediction and hopefully we can do a causal inference. For convenience, the variables name in this report will be changed as in the Appendix A. The variable name in the plot remains the same as in the dataset.
#Method
##Exploratory Data Analysis

In this section, we will apply EDA on the dataset and get a sense of certain characteristics of the data. To simplify the the analysis, we will take ceiling of the `Quality of patient care star rating`. For example, 3.5 will be rounded up to 4. Without rounded up, the model fitting will also take too much time (longer than 48 hours using stan_polr).    
First, we want to get a sense of the distribution of the quality rating by type of ownership.

```{r,echo=FALSE,warning=FALSE}
#read cleaned dataset
care<-read.csv("care_cleaned.csv",header=TRUE)
#extract subset about quality rating
rating<-care[,c(2,9:34)]
colnames(rating)<-c("State","Type.of.Ownership","Offers.Nursing.Care.Services","Offers.Physical.Therapy.Services",                                                                                     "Offers.Occupational.Therapy.Services" ,                                                                   "Offers.Speech.Pathology.Services" ,                                                                        "Offers.Medical.Social.Services" ,                                                                          "Offers.Home.Health.Aide.Services",                                                                        "Date.Certified"            ,                                                                              "Quality.of.Patient.Care.Star.Rating", "TimelyManner","DrugsTeaching","RiskofFalling","Depression","FluShot","Vaccine","FootCare","Walking","Bed","Bathing","Breathing","Operation","DrugsTaking","HospitalAdmitted","UnplannedCare","SkinIntegrity","TimelyMedication")
rating$Type.of.Ownership%<>%factor()
rating$Quality.of.Patient.Care.Star.Rating%<>%ceiling()%<>%factor()
```

```{r,echo=FALSE,warning=FALSE}
##Combine rating 1 and 2 as one, as rating 1 does not have enough number


ggplot(data=rating,aes(x=Quality.of.Patient.Care.Star.Rating))+geom_bar(stat="count",aes(fill=Type.of.Ownership))+geom_vline(aes(xintercept=mean(Quality.of.Patient.Care.Star.Rating)),color="red")
ggsave("EDA.png",width=6,height=3)
```

Since the observations from the first category is much less than the other categories, the rating 1 and 2 are combined as one category, in order for a better model fitting.

```{r EDA1,echo=FALSE,warning=FALSE}
rating$Quality.of.Patient.Care.Star.Rating[which(rating$Quality.of.Patient.Care.Star.Rating==1)]<-2
rating$Quality.of.Patient.Care.Star.Rating%<>%factor()
ggplot(data=rating,aes(x=Quality.of.Patient.Care.Star.Rating))+geom_bar(stat="count",aes(fill=Type.of.Ownership))+geom_vline(aes(xintercept=mean(Quality.of.Patient.Care.Star.Rating)),color="red")
ggsave("EDA2.png",width=6,height=3)
```

From the plot we can tell that counts of rating on both ends are less than the middle ones, which accords with common sense. We then make plots of continuos variables against `Rating`.
```{r}
pp1<-ggplot(data=rating,aes(x=TimelyManner,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
ggsave("EDA3.png",width=6,height=3)
```
An example of  continuous variables versus `Quality of Patient Care Star Rating` are plotted above. The rest will be put in the Appendix B. In general, for the variables `RiskofFalling`, `DrugsTeaching`, `RiskofFalling`, `Depression`, `FootCare`, the points concentrate on the right side, indicating these services are usually provided with a large percentage. Variables `FluShot` and `Vaccine`, while also show a tendency on a large percentage of service, they also have a larger dispersion towards left. In addition, the dots also have a tendency of concentrating on the upper-right, indicating that there should be some positive correlation between the variables and the ratings.     
Moreover, `Walking`, `Bed`, `Bathing`, `Breathing`, `Operation`, `DrugsTaking` are showing a more obvious positive correlation. The `HospitalAdmitted` and `SkinIntegrity` show negative correlations, which is consistent with what the variables represent.

##Modelling

###Ordinal Categorical Logistic Regression Model
Since I could not find an appropriate pacakage to fit a multilevel ordinal logistic model on this datset(`clmm()` from package `ordinal` does not work as well), in this section, we will fit an ordinal categorical logistic model on the dataset. The stan_plor() function will be used to build the model. To avoid wasting too much time on model fitting, we will randomly draw 4000 observations for fitting.

```{r Modelling1,echo=FALSE,warning=FALSE}
rown<-sample(rownames(rating),2000)
fitset<-rating[rown,]
colnames(fitset)[10]<-"Rating"

m2<-stan_polr(Rating~TimelyManner+DrugsTeaching+RiskofFalling+Depression+FluShot+Vaccine+FootCare+Walking+Bed+Bathing+Breathing+Operation+DrugsTaking+HospitalAdmitted+UnplannedCare+SkinIntegrity+TimelyMedication,data=fitset,prior=NULL,refresh=0)


m3<-clmm2(Rating~TimelyManner+DrugsTeaching+RiskofFalling+Depression+FluShot+Vaccine+FootCare+Walking+Bed+Bathing+Breathing+Operation+DrugsTaking+HospitalAdmitted+UnplannedCare+SkinIntegrity+TimelyMedication,random=Type.of.Ownership,data=fitset,Hess=T)
# summary(m1)
# summary(m3)
summary(m2,digits=2)%>%kable()
```


```{r Interval,echo=FALSE,warning=FALSE}
# summary(m3)[1]%>%data.frame()->a
# interval<-data.frame("predictors"=rownames(a),"estimate"=a[,1],"left"=a[,1]-2*a[,2],"right"=a[,1]+2*a[,2])
# ggplot(aes(x = predictors, y = estimate,
#            ymin =left, ymax = right),
#        data = interval[1:17,]) + geom_pointrange(size=0.2) +
#     labs(x= "Predictors",
#          y = "95% Confidece Interval of Coefficient Estiamtes")+
#   theme(axis.text.x = element_text( family = "myFont" ,angle = 60))


interval<-posterior_interval(m2,prob=0.95)
interval<-data.frame(name=rownames(interval),interval)
ggplot(aes(x = name, y=(X2.5.+X97.5.)/2,
           ymin =X2.5., ymax = X97.5.),
       data = interval[1:17,]) + geom_pointrange(size=0.2,color="blue") +
    labs(x= "Predictors",
         y = "95% Confidence Interval",title="Coefficient Estimates")+
  theme(axis.text.x = element_text( family = "myFont" ,angle = 60))+geom_text(aes(label=round((X2.5.+X97.5.)/2,2)),vjust=-1.5,size=3)

ggsave("interval_co.jpg",height=3,width=6)
ggplot(aes(x = name, y=(X2.5.+X97.5.)/2,
           ymin =X2.5., ymax = X97.5.),
       data = interval[18:20,]) + geom_pointrange(size=0.2,color="blue") +
    labs(x= "Predictors",
         y = "95% Confidence Interval",title="Coefficient Estimates (Intercept)")+
  theme(axis.text.x = element_text( family = "myFont" ,angle = 60))+geom_text(aes(label=round((X2.5.+X97.5.)/2,2)),vjust=-1.5,size=3)
ggsave("interval_itc.jpg",height=3,width=6)

```
From the coefficent plot, we can extract some useful information. First, the `SkinIntegrity` have a large standard error, indicating that there is a large uncertainty in the estimate. Several coefficients, such as `Depression`, `Flushot`,`Vaccine`,`Operation`,`UnplannedCare`,`SkinIntegrity`,`TimelyMedication`, `RiskofFalling` have 95% confidence interval crossing 0, indicating that we can not safely reject that these coefficients should be 0. The result is also consistent with what we found in the EDA, where under these predictors, the `Rating` doesn't show a noticable positive or negative correlation.




##Validation
```{r}
fake.predict.clmm <- function(model, newdata) {
  # Actual prediction function
  pred <- function(eta, theta, cat = 1:(length(theta) + 1), inv.link = plogis) {
    Theta <- c(-1000, theta, 1000)
    sapply(cat, function(j) inv.link(Theta[j + 1] - eta) - inv.link(Theta[j] - eta))
  }
  
  # Multiply each row by the coefficients
  coefs <- c(model$beta, unlist(model$ST))
  xbetas <- sweep(newdata, MARGIN=2, coefs, `*`)
  
  # Make predictions
  pred.mat <- data.frame(pred(eta=rowSums(xbetas), theta=model$Theta))
  colnames(pred.mat) <- levels(model$model[,1])
  pred.mat
}
pred<-fake.predict.clmm(m3,newdata=fitset[,11:27])%>%data.frame()
pred%<>%na.omit()
observ<-model.matrix(~Rating,data=fitset[rownames(pred),])
resid<-pred-observ
resid%<>%na.omit()
for(i in 1:4) binnedplot(pred[,i],resid[,i])
```

```{r,echo=FALSE,warning=FALSE}
predy<-posterior_predict(m2)
n_sims<-nrow(predy)
subset<-sample(n_sims,100)
yrep<-as.data.frame(lapply(data.frame(predy[subset,]),as.numeric))
```

```{r,echo=FALSE,warning=FALSE}

ppcplot<-ppc_bars(as.numeric(temp$Rating)+1,as.matrix(yrep))
ppc_rootogram(as.numeric(temp$Rating)+1,as.matrix(yrep))
```

In the ppc bar plot, the darker blue dots indicate the medians of `yrep`, and the intervals indicates the uncertainty intervals. From the posterior predictive check, the plot clearly tells us that the model fits quite well.

#Result

From the EDA part, we could tell that the 
From the modelling part, the ordinal categorical logistic regression model fits well on the dataset. Some variables have a siginificant coefficient estimate on 5% siginificance level, while variables such as `Depression`, `Flushot`,`Vaccine`,`Operation`,`UnplannedCare`,`SkinIntegrity`,`TimelyMedication`, have confidence interval crossing 0. On the other hand, `Bathing`, `Bed`, `Breathing`, `DrugsTaking`, `TimelyManner`, `Walking` have relatively large coefficient estimates.
From the validation part, we use ppc bar plot to show how well the model fits. From the plot, the medians of predictive values `yrep` are basically the same as the counting of observative values `y`, indicating the model fitting good on the datset

#Discussion
The results drawn above shows that, for some variables, they might not have siginificant impacts on the `Rating`, such as `Depression` and all those insignificant variables in 5% level shown in the results. For those significant ones, there are two groups of them. First, for those having low estimates, they are showing a positive correlation with `Rating`, but they contribute small to the increase on the `Rating`. Meanwhile, for those having high estimates, the model predicts a larger increase on `Rating` when they are increasing. Therefore, by improving home health care serivce such as helping patients at getting in and out of bed (`Bed`), beginning patient's care in a timely manner (`TimelyManner`), the team should be expected to have a higher `Rating` from the patient.



#Appendix A

`Rating`: Quality of patient care star rating, a numeric rating from 1 through 5, in increments of 0.5. Factored in this report.

`TimelyManner` : How often the home health team began their patients' care in a timely manner.

`DrugsTeaching`: How often the home health team taught patients (or their family caregivers) about their drugs

`RiskofFalling`: How often the home health team checked patients' risk of falling

`Depression`: How often the home health team checked patients for depression

`FluShot`: How often the home health team determined whether patients received a flu shot for the current flu season

`Vaccine`: How often the home health team made sure that their patients have received a pneumococcal vaccine (pneumonia shot)

`FootCare`: With diabetes, how often the home health team got doctor's orders, gave foot care, and taught patients about foot care

`Walking`: How often patients got better at walking or moving around

`Bed`: How often patients got better at getting in and out of bed

`Bathing`: How often patients got better at bathing

`Breathing`: How often patients' breathing improved

`Operation`: How often patients' wounds improved or healed after an operation

`DrugsTaking`: How often patients got better at taking their drugs correctly by mouth

`HospitalAdmitted`: How often home health patients had to be admitted to the hospital

`UnplannedCare`: How often patients receiving home health care needed urgent, unplanned care in the ER without being admitted

`SkinIntegrity`: Changes in skin integrity post-acute care: pressure ulcer/injury

`TimelyMedication`: How often physician-recommended actions to address medication issues were completely timely

#Appendix B: Data Cleaning


#Appendix C: EDA Plots

```{r EDA2,echo=FALSE,warning=FALSE}
pp1<-ggplot(data=rating,aes(x=TimelyManner,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp2<-ggplot(data=rating,aes(x=DrugsTeaching,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp3<-ggplot(data=rating,aes(x=RiskofFalling,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp4<-ggplot(data=rating,aes(x=Depression,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp5<-ggplot(data=rating,aes(x=FluShot,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp6<-ggplot(data=rating,aes(x=Vaccine,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp7<-ggplot(data=rating,aes(x=FootCare,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp8<-ggplot(data=rating,aes(x=Walking,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp9<-ggplot(data=rating,aes(x=Bed,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp10<-ggplot(data=rating,aes(x=Bathing,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp11<-ggplot(data=rating,aes(x=Breathing,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp12<-ggplot(data=rating,aes(x=Operation,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")


pp13<-ggplot(data=rating,aes(x=DrugsTaking,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp14<-ggplot(data=rating,aes(x=HospitalAdmitted,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp15<-ggplot(data=rating,aes(x=UnplannedCare,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

pp16<-ggplot(data=rating,aes(x=SkinIntegrity,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")
pp17<-ggplot(data=rating,aes(x=TimelyMedication,y=Quality.of.Patient.Care.Star.Rating))+geom_point(size=0.01)+geom_jitter(size=0.01)+ylab("Rating")

ggarrange(pp1,pp2,pp3,pp4,ncol=2,nrow=2,labels="plot1")
ggarrange(pp5,pp6,pp7,pp8,labels="plot2")
ggarrange(pp9,pp10,pp11,pp12,labels="plot3")
ggarrange(pp13,pp14,pp15,pp16,labels="plot4")

ggarrange(pp17,col=1,"plot5")

```

```{r Rstan}
library(rstan)

options(mc.cores=parallel::detectCores())

rstan_options(auto_write=TRUE)

sch_code = 'data {
    int N; // number of observations
    int M; // number of groups
    int K; // number of response categories
    int D; // number of predictors
    int<lower=1, upper=K> y[N]; // outcomes
    row_vector[D] x[N]; // predictors
    int g[N]; // map observations to groups 
}
parameters {

 

    ordered[K-1] theta;
    vector[D] beta;
    real a[M];
    real<lower=0, upper=10> sigma;
}
model {
    a ~ normal(0, sigma); 
    for(n in 1:N) {
        y[n] ~ ordered_logistic(x[n]* beta + a[g[n]], theta);
    } 
}'
fitset%<>%na.omit()
sch_data<-list(N=nrow(fitset),K=4,M=7,D=17,y=as.numeric(fitset$Rating),x=as.matrix(fitset[,11:27]),g=as.numeric(fitset$Type.of.Ownership))
ologit<-stan(model_code=sch_code,model_name="ologit",data=sch_data,iter=4000,chains=2,control = list(adapt_delta = 0.9,max_treedepth = 15))

print(ologit, digits_summary=3, probs=c(0.025,0.5,0.975))
##Use sink() to save the table
ologit_result<-read.table("result.txt")
```

```{r, warning=FALSE}
ologit_result['name']<-c("2|3","3|4","4|5","TimelyManner", "DrugsTeaching","RiskofFalling","Depression","FluShot","Vaccine","FootCare","Walking","Bed","Bathing","Breathing","Operation","DrugsTaking","HospitalAdmitted","UnplannedCare","SkinIntegrity","TimelyMedication","Government - Combination Government & Voluntary","Government - Local","Government - State/ County","Non - Profit Other","Non - Profit Private","Non - Profit Religious","Proprietary","sigma","lp__")
ggplot(aes(x = name, y=X50.,
           ymin =X2.5., ymax = X97.5.),
       data = ologit_result[4:20,]) + geom_pointrange(size=0.2,color="blue") +
    labs(x= "Predictors",
         y = "95% Confidence Interval",title="Coefficient Estimates (Slope)")+
  theme(axis.text.x = element_text( family = "myFont" ,angle = 60))+geom_text(aes(label=round(X50.,2)),vjust=-1.5,size=3)
ggsave("interval_co2.jpg",height=3,width=6)

ggplot(aes(x = name, y=X50.,
           ymin =X2.5., ymax = X97.5.),
       data = ologit_result[1:3,]) + geom_pointrange(size=0.2,color="blue") +
    labs(x= "Predictors",
         y = "95% Confidence Interval",title="Coefficient Estimates (Intercept)")+
  theme(axis.text.x = element_text( family = "myFont" ,angle = 60))+geom_text(aes(label=round(X50.,2)),vjust=-1.5,size=3)
ggsave("interval_itc2.jpg",height=3,width=6)

ggplot(aes(x = name, y=X50.,
           ymin =X2.5., ymax = X97.5.),
       data = ologit_result[21:27,]) + geom_pointrange(size=0.2,color="blue") +
    labs(x= "Predictors",
         y = "95% Confidence Interval",title="Coefficient Estimates (Random Intercept)")+
  theme(axis.text.x = element_text( family = "myFont" ,angle = 60))+geom_text(aes(label=round(X50.,2)),vjust=-1.5,size=3)
ggsave("interval_random.jpg")
```

```{r}
pred_code='data {
  int N; // number of observations
  int M; // number of groups
  int K; // number of response categories
  int D; // number of predictors
  int<lower=1, upper=K> y[N]; // outcomes
  row_vector[D] x[N]; // predictors
  
  int g[N]; // map observations to groups 
  

  row_vector[D] x_new[N];
}
parameters {
  ordered[K-1] theta;
  vector[D] beta;
  real a[M];
  real<lower=0, upper=10> sigma;
}
model {
  a ~ normal(0, sigma); 
  for(n in 1:N) {
    y[n] ~ ordered_logistic(x[n]* beta + a[g[n]], theta);
  }
}
generated quantities{
  int<lower=1, upper=K> y_new[N]; // outcomes
  
  for(n in 1:N){
    y_new[n] = ordered_logistic_rng(x_new[n]* beta + a[g[n]], theta);

  }

}'
sch_data_pred<-list(N=nrow(fitset),N_new=nrow(fitset),K=4,M=7,D=17,y=as.numeric(fitset$Rating),x=as.matrix(fitset[,11:27]),g=as.numeric(fitset$Type.of.Ownership),x_new=as.matrix(fitset[,11:27]))
pred_ologit<-stan(model_code=pred_code,model_name="pred",data=sch_data_pred,iter=4000,chains=2,control = list(adapt_delta = 0.9,max_treedepth = 15),seed=12345)

```
```{r}
sch_code_2 = 'data {
    int N; // number of observations
    int M; // number of groups
    int K; // number of response categories
    int D; // number of predictors
    int<lower=1, upper=K> y[N]; // outcomes
    row_vector[D] x[N]; // predictors
    int g[N]; // map observations to groups 

    row_vector[D] x_new[N];
}
parameters {

 

    ordered[K-1] theta;
    vector[D] beta;
    real a[M];
    real<lower=0, upper=10> sigma;
    
    int<lower=1, upper=K> y_new[N];
}
model {
    a ~ normal(0, sigma); 
    for(n in 1:N) {
        y[n] ~ ordered_logistic(x[n]* beta + a[g[n]], theta);
    }
     for(n in 1:N) {
        y_new[n] ~ ordered_logistic(x[n]* beta + a[g[n]], theta);
    } 
}'
sch_data_pred<-list(N=nrow(fitset),N_new=nrow(fitset),K=4,M=7,D=17,y=as.numeric(fitset$Rating),x=as.matrix(fitset[,11:27]),g=as.numeric(fitset$Type.of.Ownership),x_new=as.matrix(fitset[,11:27]))
pred_ologit<-stan(model_code=sch_code_2,model_name="pred",data=sch_data_pred,iter=4000,chains=2,control = list(adapt_delta = 0.9,max_treedepth = 15))

```
